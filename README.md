# Cloud-Based FSAâ€‘Driven Intelligent Monitoring System  
_For Renewable Energyâ€‘Powered Distributed Networks_  
_with Ollama (Mistral 7B) AI Integration_

## ğŸ“Œ Overview
This is a **full-stack intelligent monitoring platform** for distributed renewable energy networks.  
It includes:

- **Finite State Automata (FSA)** to model operational states of each energy node (Normal, Faulted, Recovering)
- **Simulation** of solar, wind, and hybrid node output with random faults
- **FastAPI backend** serving REST & WebSocket data feeds
- **Frontend dashboard** (HTML/CSS/JavaScript + Chart.js)
- **Ollama (Mistral 7B)** for **natural language Q&A** grounded in **live system data**

---

## ğŸ— Features
- **Real-time WebSocket updates** of node status and power output.
- **Live line chart** using Chart.js.
- **Ollama-powered AI assistant** for natural language queries about the network.
- Simulation easily replaceable with **real IoT data**.

---

## ğŸ“‚ Project Structure
cloud-fsa-monitoring-system/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app.py # FastAPI app (REST + WebSocket endpoints)
â”‚ â”œâ”€â”€ fsa/ # Core FSA logic
â”‚ â”œâ”€â”€ simulation/ # Data simulation modules
â”‚ â”œâ”€â”€ anomaly_detection/ # Real-time anomaly detection
â”‚ â”œâ”€â”€ utils/ollama_client.py # Ollama integration
â”‚ â””â”€â”€ database/ # Optional DB models
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ index.html
â”‚ â”œâ”€â”€ styles/style.css
â”‚ â””â”€â”€ scripts/ # JS: api.js, graph.js, main.js
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
text

---

## âš™ï¸ Requirements
- **Python 3.9+**
- **Ollama** installed locally â†’ [https://ollama.com](https://ollama.com)
- **Mistral 7B model** pulled locally:
ollama pull mistral:7b
text

---

## ğŸ“¦ Installation

1ï¸âƒ£ **Clone repo**
git clone <your-repo-url>
cd cloud-fsa-monitoring-system
text

2ï¸âƒ£ **Set up Python environment**
python3 -m venv venv
source venv/bin/activate # On Mac/Linux
pip install -r requirements.txt
text

3ï¸âƒ£ **Start Ollama**
ollama serve
text

---

## â–¶ï¸ Running the System

### **Step 1 â€” Start Backend API (FastAPI)**
From the project root:
uvicorn backend.app:app --reload --host 0.0.0.0 --port 8000
text
- `--reload` â†’ automatically reload on code changes
- `--host 0.0.0.0` â†’ accessible on LAN if needed
- Backend docs: [http://localhost:8000/docs](http://localhost:8000/docs)
- WebSocket: `ws://localhost:8000/ws`

---

### **Step 2 â€” Serve Frontend**
In a **new terminal**, from the `frontend` folder:
cd frontend
python3 -m http.server 8080
text
Now open: [http://localhost:8080](http://localhost:8080)

---

### **Step 3 â€” Using the Dashboard**
- **Live Table**: Node IDs, operational states, power output
- **Live Graph**: Power output plotted over time
- **Chatbox**: Ask the AI assistant questions about the current network  
  (Model: `mistral:7b` running locally in Ollama)

Example questions:
Which nodes are faulted right now?
Summarize the current network status.
text

---

## ğŸ›  Troubleshooting
**WebSocket errors / No live updates**  
â†’ Ensure backend is running on port `8000` and frontend is on `8080`.

**AI Chat shows â€œError connecting to serverâ€**  
â†’ Ensure `ollama serve` is running and `mistral:7b` is installed.

**Chart not updating**  
â†’ Open browser DevTools â†’ Console â†’ check payloads from `/ws`.

---

## ğŸ’¬ Example Full Run Commands

Terminal 1: Run Ollama
ollama serve
Terminal 2: Start FastAPI backend
uvicorn backend.app:app --reload --host 0.0.0.0 --port 8000
Terminal 3: Serve frontend
cd frontend
python3 -m http.server 8080
text

---

## ğŸš€ Extend & Customize
- Replace simulation with live sensor/IoT devices
- Store historical data in a database
- Extend Ollama prompt for advanced analytics

---

**Author:** _[Your Name]_  
**Location:** Bengaluru  
**Specialty:** AI-Integrated Renewable Energy Monitoring Systems
